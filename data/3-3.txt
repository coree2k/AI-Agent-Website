### n8n과 Supabase Vector Store를 활용하여 문서 기반 AI 챗봇을 구축하는 가이드입니다. <br>  Google Drive에 저장된 문서를 자동으로 벡터 데이터베이스에 저장하고, AI Agent가 이를 검색하여 정확한 답변을 제공하는 <br> RAG(Retrieval-Augmented Generation) 시스템을 만들었습니다.

## 목차

- [시스템 개요](#시스템-개요)
- [사전 준비사항](#사전-준비사항)
- [Supabase 설정](#supabase-설정)
- [워크플로우 1: 문서 Vector DB 구축](#워크플로우-1-문서-vector-db-구축)
- [워크플로우 2: AI RAG Agent 구축](#워크플로우-2-ai-rag-agent-구축)
- [고급 활용 팁](#고급-활용-팁)
- [문제 해결](#문제-해결)
- [최적화 가이드](#최적화-가이드)

## 시스템 개요

이 가이드에서는 두 개의 연결된 워크플로우를 통해 완전한 RAG 시스템을 구축합니다.

### 시스템 아키텍처

**워크플로우 1: 문서 Vector DB**
- Google Drive의 문서를 자동으로 수집
- 텍스트를 적절한 크기로 분할
- OpenAI 임베딩 모델로 벡터화
- Supabase Vector Store에 저장

**워크플로우 2: AI RAG Agent**
- 채팅 메시지 수신
- Vector Store에서 관련 문서 검색
- AI Agent가 검색된 문서를 바탕으로 답변 생성
- 대화 기록 관리 및 컨텍스트 유지

### 주요 기능

- **자동 문서 처리**: Google Drive의 파일을 자동으로 벡터 DB에 저장
- **지능형 검색**: 사용자 질문과 가장 관련 있는 문서 자동 검색
- **컨텍스트 기반 답변**: 검색된 문서를 바탕으로 정확한 답변 제공
- **대화 기억**: Postgres를 활용한 대화 이력 관리
- **확장 가능**: Tool 연결로 다양한 기능 추가 가능

## 사전 준비사항

### 필수 도구

- n8n 설치 및 실행
- Google 계정 (Google Drive 접근용)
- Supabase 계정
- OpenAI API 키

### 권장 지식

- 기본적인 n8n 워크플로우 이해
- RAG 시스템의 개념 이해
- Vector Database 기본 개념

## Supabase 설정

### 1. Supabase 프로젝트 생성

1. [Supabase](https://supabase.com/)에 접속하여 로그인
2. 'New Project' 클릭
3. 프로젝트 이름, 데이터베이스 비밀번호, 리전 선택
4. 프로젝트 생성 완료 대기

### 2. Vector Store 설정

**SQL Editor에서 실행**:

```sql
-- pgvector 확장 활성화
create extension if not exists vector;

-- 문서 테이블 생성
create table documents (
  id bigserial primary key,
  content text,
  metadata jsonb,
  embedding vector(1536)
);

-- 벡터 검색 인덱스 생성
create index on documents using ivfflat (embedding vector_cosine_ops)
with (lists = 100);
```

### 3. 연결 정보 확인

**Project Settings > API**에서 다음 정보 복사:
- Project URL
- Project API Key (anon, public)
- Database Password

## 워크플로우 1: 문서 Vector DB 구축

![워크플로우 구조](./n8n_Source/03-03/2.%20WF.png)

### 노드 구성 순서

```
Google Drive Trigger → Download File → Text Splitter → 
Embeddings OpenAI → Supabase Vector Store
```

### 1. Google Drive Trigger 설정

**목적**: 새 파일이 업로드되거나 파일이 변경될 때 자동 실행

1. **Google Drive Trigger 노드 추가**
2. **Trigger On**: 'File Created or Updated' 선택
3. **Google Drive 인증**:
   - OAuth2 연결 설정
   - Google 계정 권한 승인
4. **폴더 지정** (선택사항):
   - 특정 폴더만 모니터링하려면 Folder ID 입력

**설정 팁**:
- 폴더 ID는 Google Drive URL에서 확인 가능
- 예: `https://drive.google.com/drive/folders/[FOLDER_ID]`

### 2. Download File 노드 설정

**목적**: Google Drive의 파일을 다운로드하여 텍스트 추출

1. **Download File 노드 추가**
2. **Resource**: 'File' 선택
3. **Operation**: 'Download' 선택
4. **File ID**: `{{ $json.id }}` (이전 노드에서 전달)

**지원 파일 형식**:
- Google Docs (.gdoc)
- PDF (.pdf)
- 텍스트 파일 (.txt, .md)
- Word 문서 (.docx)

### 3. Default Data Loader 설정

**목적**: 다운로드한 파일에서 텍스트 추출

1. **Default Data Loader 노드 추가**
2. **자동으로 파일 내용을 텍스트로 변환**

**참고사항**:
- 이미지나 테이블이 많은 문서는 텍스트 추출이 제한적일 수 있음
- PDF의 경우 OCR 없이 텍스트만 추출

### 4. Recursive Character Text Splitter 설정

**목적**: 긴 문서를 적절한 크기의 청크로 분할

1. **Recursive Character Text Splitter 노드 추가**
2. **주요 설정값**:
   - **Chunk Size**: `1000` (청크당 문자 수)
   - **Chunk Overlap**: `100` (청크 간 겹치는 문자 수)

**설정 가이드**:

| 문서 특성 | Chunk Size | Chunk Overlap |
|---------|-----------|--------------|
| 기술 문서 | 1000-1500 | 100-200 |
| 일반 문서 | 800-1000 | 50-100 |
| 대화형 데이터 | 500-800 | 50 |

**청크 크기 선택 기준**:
- 너무 작으면: 컨텍스트 손실, 검색 정확도 하락
- 너무 크면: 관련 없는 정보 포함, 토큰 낭비
- Overlap: 문맥 연결성 유지, 정보 단절 방지

### 5. Embeddings OpenAI 설정

**목적**: 텍스트 청크를 벡터로 변환

1. **Embeddings OpenAI 노드 추가**
2. **OpenAI 인증 설정**:
   - API Key 입력
3. **Model**: `text-embedding-3-small` (기본값, 권장)

**모델 선택 가이드**:

| 모델 | 차원 | 성능 | 비용 | 권장 용도 |
|-----|------|-----|-----|---------|
| text-embedding-3-small | 1536 | 표준 | 저렴 | 일반 문서 |
| text-embedding-3-large | 3072 | 높음 | 비쌈 | 정밀 검색 필요 |
| text-embedding-ada-002 | 1536 | 표준 | 중간 | 레거시 |

### 6. Supabase Vector Store 설정

**목적**: 벡터를 Supabase에 저장

1. **Supabase Vector Store 노드 추가**
2. **Mode**: 'Insert Documents' 선택
3. **Supabase 인증 설정**:
   - Host: `https://your-project.supabase.co`
   - Service Role Key: Supabase에서 복사한 키
4. **Table Name**: `documents`
5. **Query Name**: `match_documents` (검색 함수명)

**Supabase 설정 확인**:
```sql
-- 저장된 문서 확인
SELECT id, 
       content, 
       metadata,
       embedding <-> '[...]'::vector as distance 
FROM documents 
LIMIT 5;
```

### 워크플로우 1 테스트

1. Google Drive에 테스트 문서 업로드
2. n8n에서 워크플로우 활성화
3. 실행 로그 확인
4. Supabase에서 데이터 저장 확인

## 워크플로우 2: AI RAG Agent 구축

![AI RAG Agent 워크플로우](./rag-agent-workflow.png)

### 노드 구성 순서

```
Chat Trigger → AI Agent → [OpenAI Chat Model + Postgres Chat Memory + 
Supabase Vector Store + Embeddings OpenAI + Tool]
```

### 1. When Chat Message Received 설정

**목적**: 채팅 인터페이스에서 메시지 수신

1. **When Chat Message Received 노드 추가**
2. **자동으로 n8n 채팅 인터페이스 활성화**
3. **Public Chat URL**: 테스트용 공개 URL 생성 가능

**채팅 인터페이스 옵션**:
- n8n 내장 채팅 UI 사용
- Webhook으로 외부 채팅 앱 연결 가능
- 카카오톡, 슬랙 등과 통합 가능

### 2. AI Agent 설정

**목적**: 대화를 관리하고 적절한 도구를 선택하여 답변 생성

1. **AI Agent 노드 추가**
2. **주요 설정**:
   - **Prompt**: 시스템 프롬프트 작성

**시스템 프롬프트 예시**:
```
당신은 문서 기반 질문에 답변하는 전문 AI 어시스턴트입니다.

### 역할
- 제공된 문서 내용을 바탕으로 정확하고 상세한 답변 제공
- 문서에 없는 내용은 추측하지 않고 "문서에 해당 정보가 없습니다"라고 답변
- 답변 시 출처를 명확히 표시

### 답변 형식
1. 핵심 답변 먼저 제시
2. 상세 설명 추가
3. 관련 문서 출처 표시

### 제약사항
- 문서에 근거한 답변만 제공
- 불확실한 내용은 명확히 표시
- 한국어로 답변
```

### 3. OpenAI Chat Model 연결

**목적**: AI Agent가 사용할 언어 모델

1. **OpenAI Chat Model 노드 추가**
2. **Agent에 연결**
3. **Model**: `gpt-4o` 또는 `gpt-4o-mini` 선택
4. **OpenAI 인증**: API Key 입력

**모델 선택 가이드**:

| 모델 | 성능 | 속도 | 비용 | 권장 용도 |
|-----|------|-----|-----|---------|
| gpt-4o | 최고 | 중간 | 높음 | 복잡한 추론, 정확도 중요 |
| gpt-4o-mini | 우수 | 빠름 | 저렴 | 일반 질의응답 |
| gpt-3.5-turbo | 표준 | 매우 빠름 | 매우 저렴 | 간단한 질문 |

### 4. Postgres Chat Memory 설정

**목적**: 대화 기록을 저장하고 컨텍스트 유지

1. **Postgres Chat Memory 노드 추가**
2. **Agent에 Memory로 연결**
3. **Supabase Postgres 연결**:
   - Connection String: Supabase Database URL
   - 또는 Host, Database, User, Password 개별 입력

**Supabase에서 테이블 생성**:
```sql
-- 대화 기록 테이블 생성
CREATE TABLE chat_history (
  id SERIAL PRIMARY KEY,
  session_id TEXT NOT NULL,
  message_type TEXT NOT NULL,
  content TEXT NOT NULL,
  created_at TIMESTAMP DEFAULT NOW()
);

-- 인덱스 생성
CREATE INDEX idx_session_id ON chat_history(session_id);
```

**Memory 설정 옵션**:
- **Session ID**: 사용자별 대화 구분
- **Context Window Size**: 몇 개의 이전 메시지를 기억할지 설정

### 5. Supabase Vector Store (검색용) 설정

**목적**: 사용자 질문과 관련된 문서 검색

1. **Supabase Vector Store 노드 추가**
2. **Agent에 Tool로 연결**
3. **Mode**: 'Get Many' 선택
4. **Supabase 인증**: 워크플로우 1과 동일하게 설정
5. **주요 설정**:
   - **Top K**: `3` (검색할 문서 개수)
   - **Description**: Agent가 이해할 수 있도록 Tool 설명 작성

**Tool Description 예시**:
```
문서 데이터베이스에서 질문과 관련된 정보를 검색합니다. 
사용자의 질문에 대한 답변을 찾기 위해 이 도구를 사용하세요.
```

**Top K 설정 가이드**:
- **K=1**: 가장 관련성 높은 문서만 (빠르지만 정보 부족 가능)
- **K=3**: 균형잡힌 설정 (권장)
- **K=5-10**: 포괄적 검색 (느리지만 정확도 향상)

### 6. Embeddings OpenAI 연결

**목적**: 사용자 질문을 벡터로 변환하여 검색

1. **Embeddings OpenAI 노드 추가**
2. **Vector Store에 연결**
3. **Model**: `text-embedding-3-small` (문서 임베딩과 동일 모델 사용 필수)

**중요**: 문서 저장 시 사용한 임베딩 모델과 검색 시 사용하는 모델이 반드시 동일해야 합니다.

### 7. Tool 연결 (선택사항)

**목적**: Agent가 추가 작업을 수행할 수 있도록 확장

**연결 가능한 Tool 예시**:
- **HTTP Request**: 외부 API 호출
- **Code**: Python/JavaScript 코드 실행
- **Database**: 데이터베이스 쿼리
- **Email**: 이메일 발송

**Tool 추가 시 설정**:
1. Tool 노드 추가
2. Agent에 연결
3. **Name**: Tool 이름 지정
4. **Description**: Agent가 언제 이 Tool을 사용할지 명확히 설명

**Tool Description 작성 팁**:
```
좋은 예:
"사용자가 이메일 발송을 요청하면 이 도구를 사용합니다. 
수신자 이메일과 내용을 입력받아 이메일을 전송합니다."

나쁜 예:
"이메일 보내기"
```

### 워크플로우 2 테스트

1. 워크플로우 활성화
2. Chat 버튼 클릭하여 채팅 인터페이스 열기
3. 테스트 질문 입력:
   - "업로드한 문서에 대해 요약해줘"
   - "문서에서 [특정 주제]에 대해 설명해줘"
4. Agent의 답변 확인
5. 대화 이력이 유지되는지 후속 질문으로 확인

## 고급 활용 팁

### 1. 멀티모달 검색 (이미지 + 텍스트)

이미지가 포함된 문서도 검색하려면:

1. **Vision 모델 사용**: GPT-4 Vision으로 이미지 분석
2. **이미지 설명 저장**: 이미지를 텍스트로 변환하여 저장
3. **메타데이터 활용**: 이미지 파일명, 위치 정보를 메타데이터에 저장

### 2. 문서 소스 표시

사용자에게 답변 출처를 명확히 보여주기:

**System Prompt에 추가**:
```
답변 시 반드시 출처를 다음 형식으로 표시하세요:

[출처: 문서명, 페이지/섹션]
```

### 3. 필터링 검색

특정 조건에 맞는 문서만 검색:

**Supabase Vector Store 설정**에서 Filter 추가:
```json
{
  "metadata->>'category'": "기술문서",
  "metadata->>'date'": { "$gte": "2024-01-01" }
}
```

### 4. 하이브리드 검색

벡터 검색 + 키워드 검색 조합:

1. Vector Store로 유사도 검색
2. Full-text search로 키워드 검색
3. 두 결과를 조합하여 정확도 향상

### 5. 답변 품질 향상

**System Prompt 최적화**:
```
### 답변 가이드라인

1. **정확성**: 문서에 있는 내용만 답변
2. **완전성**: 질문의 모든 부분에 답변
3. **간결성**: 핵심을 먼저, 상세 내용은 필요시 추가
4. **출처**: 답변의 근거가 되는 문서 섹션 명시
5. **한계**: 문서에 없는 내용은 솔직히 인정

### 불확실한 경우
"제공된 문서에는 이에 대한 명확한 정보가 없습니다. 
다음과 같은 관련 내용은 있습니다: [...]"
```

### 6. 다국어 지원

**임베딩 모델**: OpenAI의 text-embedding-3 모델은 다국어 지원
- 한국어, 영어, 일본어 등 동시 검색 가능
- 쿼리 언어와 문서 언어가 달라도 검색 가능

### 7. 실시간 문서 업데이트

**Webhook 활용**:
1. 문서 업데이트 시 Webhook 호출
2. 기존 벡터 삭제
3. 새 벡터 생성 및 저장

**Supabase에서 중복 방지**:
```sql
-- 파일 ID 기준 기존 데이터 삭제
DELETE FROM documents 
WHERE metadata->>'file_id' = 'xxx';
```

## 문제 해결

### 자주 발생하는 문제들

#### 1. 검색 결과가 부정확함

**원인**:
- 청크 크기가 적절하지 않음
- Top K 값이 너무 작음
- 임베딩 모델이 일치하지 않음

**해결책**:
- Chunk Size를 조정 (1000-1500 권장)
- Top K를 3-5로 증가
- 저장과 검색에 동일한 임베딩 모델 사용 확인

#### 2. Agent가 문서를 참조하지 않음

**원인**:
- Tool Description이 불명확
- System Prompt에 문서 참조 지시 없음

**해결책**:
- Tool Description을 명확히 작성
- System Prompt에 "반드시 문서를 검색하여 답변" 명시
- 예시 답변 포함

#### 3. Supabase 연결 실패

**원인**:
- 잘못된 인증 정보
- IP 허용 목록 설정 오류
- 테이블 권한 문제

**해결책**:
- Project URL과 API Key 재확인
- Supabase Settings에서 Network 설정 확인
- Service Role Key 사용 (anon key가 아닌)

#### 4. 메모리가 작동하지 않음

**원인**:
- Postgres 연결 실패
- Session ID 설정 오류
- 테이블 생성 누락

**해결책**:
- Postgres 연결 테스트
- Session ID가 일관되게 유지되는지 확인
- chat_history 테이블 존재 확인

#### 5. 토큰 제한 초과

**원인**:
- 너무 많은 문서 검색 (Top K가 큼)
- 청크 크기가 너무 큼
- 대화 기록이 너무 길어짐

**해결책**:
- Top K 감소 (3-5 권장)
- Chunk Size 감소
- Memory의 Context Window 제한

### 디버깅 팁

**1. 각 노드의 출력 확인**:
```
n8n에서 각 노드 클릭 → 'Output' 탭 확인
- 데이터가 제대로 전달되는지 확인
- 에러 메시지 확인
```

**2. Supabase 직접 쿼리**:
```sql
-- 저장된 문서 개수 확인
SELECT COUNT(*) FROM documents;

-- 최근 저장된 문서 확인
SELECT id, 
       LEFT(content, 100) as preview,
       metadata 
FROM documents 
ORDER BY id DESC 
LIMIT 5;

-- 임베딩이 제대로 생성되었는지 확인
SELECT id, 
       array_length(embedding, 1) as dimension 
FROM documents 
LIMIT 5;
```

**3. 검색 품질 테스트**:
```sql
-- 테스트 쿼리로 검색 (임베딩 벡터를 직접 입력)
SELECT content,
       embedding <-> '[0.1, 0.2, ...]'::vector as distance
FROM documents
ORDER BY distance
LIMIT 5;
```

## 최적화 가이드

### 성능 최적화

#### 1. 인덱스 최적화

**IVFFlat 인덱스 튜닝**:
```sql
-- lists 값 조정 (문서 개수에 따라)
-- 권장: sqrt(row_count)

-- 1000개 문서: lists = 30
-- 10000개 문서: lists = 100
-- 100000개 문서: lists = 300

CREATE INDEX ON documents 
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);
```

#### 2. 배치 처리

대량 문서 처리 시:
1. Google Drive Trigger 대신 Schedule Trigger 사용
2. Loop 노드로 파일을 하나씩 처리
3. 배치 크기 제한 (한 번에 10-20개)

#### 3. 캐싱 전략

자주 검색되는 쿼리 캐싱:
- Redis 또는 Memory에 검색 결과 저장
- 같은 질문은 캐시에서 반환

### 비용 최적화

#### 1. 임베딩 비용 절감

- **text-embedding-3-small** 사용 (large 대비 5배 저렴)
- 중복 문서 제거 (파일 해시로 중복 체크)
- 불필요한 문서는 Vector Store에 저장하지 않음

**예상 비용**:
- text-embedding-3-small: $0.02 / 1M tokens
- 1000자 문서 1000개 임베딩: 약 $0.02

#### 2. LLM 비용 절감

- 간단한 질문은 **gpt-4o-mini** 사용
- System Prompt를 간결하게 유지
- 불필요한 대화 기록 제거 (Context Window 제한)

**비용 비교** (1M tokens 기준):
- gpt-4o: $2.5 (input) / $10 (output)
- gpt-4o-mini: $0.15 (input) / $0.6 (output)
- 약 16배 차이

#### 3. 검색 최적화

- Top K를 필요한 만큼만 설정 (3-5 권장)
- 불필요한 메타데이터는 저장하지 않음

### 정확도 최적화

#### 1. 청크 전략

**문서 타입별 최적 설정**:

```python
# 기술 문서 (코드, API 문서)
{
  "chunk_size": 1500,
  "chunk_overlap": 200,
  "separator": "\n\n"  # 섹션 단위로 분할
}

# 일반 문서 (블로그, 기사)
{
  "chunk_size": 1000,
  "chunk_overlap": 100,
  "separator": "\n\n"
}

# 대화형 데이터 (Q&A, FAQ)
{
  "chunk_size": 500,
  "chunk_overlap": 50,
  "separator": "\n"
}
```

#### 2. 메타데이터 활용

문서에 메타데이터 추가:
```json
{
  "title": "문서 제목",
  "category": "기술문서",
  "date": "2024-01-15",
  "author": "작성자",
  "source": "Google Drive",
  "file_id": "abc123",
  "tags": ["AI", "RAG", "n8n"]
}
```

**메타데이터 필터링 검색**:
```sql
SELECT * FROM documents
WHERE metadata->>'category' = '기술문서'
AND embedding <-> query_embedding < 0.5
ORDER BY embedding <-> query_embedding
LIMIT 5;
```

#### 3. Re-ranking

검색 결과의 품질 향상:
1. Vector Store에서 Top K=10 검색
2. LLM으로 관련도 재평가
3. 상위 3개만 Agent에 전달

**Re-ranking Prompt**:
```
다음 문서들 중 질문과 가장 관련 있는 순서대로 순위를 매기세요.

질문: {{ $json.query }}

문서:
1. {{ $json.doc1 }}
2. {{ $json.doc2 }}
...

관련도 순위를 1,2,3... 형식으로 답하세요.
```

#### 4. Query Expansion

사용자 질문을 확장하여 검색 품질 향상:

**LLM으로 질문 재작성**:
```
사용자 질문: "RAG가 뭐야?"

확장된 질문:
- "RAG(Retrieval-Augmented Generation)란 무엇인가?"
- "RAG 시스템의 작동 원리"
- "RAG의 장점과 활용 사례"
```

여러 확장 질문으로 검색 후 결과 병합

## 실전 활용 사례

### 1. 고객 지원 챗봇

**구성**:
- 제품 매뉴얼, FAQ를 Vector DB에 저장
- 고객 문의를 자동으로 분석하고 답변
- 해결 못한 질문은 상담원에게 에스컬레이션

**추가 Tool**:
- 티켓 생성 Tool
- 이메일 발송 Tool
- 고객 정보 조회 Tool

### 2. 사내 지식 검색 시스템

**구성**:
- Confluence, Notion, Google Docs 연동
- 프로젝트 문서, 회의록 자동 수집
- 직원들이 자연어로 정보 검색

**권한 관리**:
- 메타데이터에 접근 권한 정보 저장
- 사용자별 필터링 검색

### 3. 논문/리서치 어시스턴트

**구성**:
- PDF 논문 자동 수집 및 분석
- 특정 주제에 대한 논문 요약
- 인용 관계 자동 추적

**추가 기능**:
- 표와 그래프 이미지 분석 (Vision 모델)
- 참고문헌 자동 정리
- 비슷한 논문 추천

### 4. 법률/계약서 검토

**구성**:
- 법률 문서, 판례 데이터베이스 구축
- 계약서 조항별 리스크 분석
- 유사 판례 자동 검색

**주의사항**:
- 전문가 검토 필수 명시
- 답변의 법적 책임 한계 고지

### 5. 학습 도우미

**구성**:
- 교재, 강의 자료를 Vector DB에 저장
- 학생 질문에 맞춤형 설명 제공
- 퀴즈 자동 생성

**추가 기능**:
- 학습 진도 추적
- 약한 부분 파악 및 추가 자료 추천
- 반복 학습 스케줄 생성

## 보안 및 개인정보 보호

### 1. 데이터 보안

**Supabase 보안 설정**:
```sql
-- Row Level Security (RLS) 활성화
ALTER TABLE documents ENABLE ROW LEVEL SECURITY;

-- 정책 생성: 인증된 사용자만 조회
CREATE POLICY "Authenticated users can view documents"
ON documents FOR SELECT
TO authenticated
USING (true);

-- 정책 생성: 특정 역할만 삽입
CREATE POLICY "Only service role can insert"
ON documents FOR INSERT
TO service_role
WITH CHECK (true);
```

### 2. API 키 관리

**n8n Credentials 활용**:
- 환경 변수로 API 키 관리
- 워크플로우에 키를 직접 입력하지 않음
- 정기적으로 키 교체

### 3. 민감 정보 필터링

**전처리 단계**:
```javascript
// Code 노드에서 민감 정보 제거
const sensitivePatterns = [
  /\d{3}-\d{2}-\d{4}/g,  // 주민등록번호
  /\d{3}-\d{4}-\d{4}/g,  // 전화번호
  /\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b/g  // 이메일
];

let content = $input.item.json.content;
sensitivePatterns.forEach(pattern => {
  content = content.replace(pattern, '[REDACTED]');
});

return { json: { ...item.json, content } };
```

### 4. 접근 로깅

**감사 추적**:
```sql
-- 로그 테이블 생성
CREATE TABLE access_logs (
  id SERIAL PRIMARY KEY,
  user_id TEXT,
  query TEXT,
  timestamp TIMESTAMP DEFAULT NOW(),
  ip_address INET
);

-- 검색 시 로그 기록
INSERT INTO access_logs (user_id, query, ip_address)
VALUES ('user123', 'RAG 시스템이란?', '192.168.1.1');
```

## 모니터링 및 유지보수

### 1. 성능 모니터링

**주요 지표**:
- 검색 응답 시간
- LLM 응답 시간
- 검색 정확도 (사용자 피드백)
- 에러율

**n8n 실행 로그 분석**:
```javascript
// 실행 시간 측정
const startTime = Date.now();
// ... 작업 수행
const duration = Date.now() - startTime;
console.log(`실행 시간: ${duration}ms`);
```

### 2. 품질 모니터링

**사용자 피드백 수집**:
- 답변 하단에 👍/👎 버튼 추가
- 부정확한 답변 로그 수집
- 주기적으로 검토 및 개선

**Supabase에 피드백 테이블**:
```sql
CREATE TABLE feedback (
  id SERIAL PRIMARY KEY,
  query TEXT,
  response TEXT,
  rating INTEGER,
  comment TEXT,
  created_at TIMESTAMP DEFAULT NOW()
);
```

### 3. 정기 업데이트

**문서 신선도 관리**:
- 오래된 문서 자동 플래그
- 주기적으로 문서 재임베딩
- 버전 관리

```sql
-- 30일 이상 된 문서 확인
SELECT id, metadata->>'title', metadata->>'date'
FROM documents
WHERE (metadata->>'date')::date < NOW() - INTERVAL '30 days';
```

### 4. 백업 및 복구

**정기 백업**:
```bash
# Supabase 데이터베이스 백업
pg_dump -h your-project.supabase.co \
        -U postgres \
        -d postgres \
        -F c \
        -f backup_$(date +%Y%m%d).dump
```

**복구 절차**:
1. 백업 파일 확인
2. 테스트 환경에서 복구 테스트
3. 프로덕션 환경 복구

## 확장 및 통합

### 1. 다른 메신저 통합

**카카오톡 연동**:
- 샘플 README의 카카오톡 연동 방법 참고
- Webhook으로 n8n RAG Agent 호출
- 카카오톡으로 AI 답변 전송

**슬랙 연동**:
```
Slack Trigger → AI Agent → Slack Message
```

### 2. 음성 인터페이스

**음성 입력 처리**:
1. Whisper API로 음성을 텍스트로 변환
2. RAG Agent로 답변 생성
3. Text-to-Speech로 음성 출력

### 3. 웹 인터페이스 커스터마이징

**n8n Webhook + 커스텀 프론트엔드**:
```javascript
// React 프론트엔드에서 n8n Webhook 호출
const response = await fetch('https://your-n8n.com/webhook/chat', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    message: userInput,
    sessionId: userId
  })
});

const data = await response.json();
displayMessage(data.response);
```

### 4. 멀티 에이전트 시스템

**전문 Agent 여러 개 구성**:
- 기술 문서 전문 Agent
- 비즈니스 전문 Agent
- 고객 지원 전문 Agent

**라우터 Agent**:
- 사용자 질문 분석
- 적절한 전문 Agent로 라우팅

## 고급 RAG 기법

### 1. HyDE (Hypothetical Document Embeddings)

**개념**: 사용자 질문으로 가상의 답변을 생성하고, 그 답변으로 검색

**구현**:
1. LLM으로 질문에 대한 가상 답변 생성
2. 가상 답변을 임베딩
3. 그 임베딩으로 Vector Store 검색

**장점**: 질문-문서 불일치 해소

### 2. Parent-Child Chunking

**개념**: 작은 청크로 검색하고, 전체 문맥은 큰 청크 반환

**구현**:
```sql
-- 계층적 청크 저장
CREATE TABLE chunks (
  id SERIAL PRIMARY KEY,
  parent_id INTEGER REFERENCES chunks(id),
  content TEXT,
  embedding vector(1536),
  chunk_level INTEGER  -- 0: 문서, 1: 섹션, 2: 단락
);
```

**검색 프로세스**:
1. 작은 청크(단락)로 검색
2. 해당 청크의 부모 섹션 전체를 Agent에 전달

### 3. Self-Query Retriever

**개념**: 사용자 질문을 분석하여 메타데이터 필터와 검색 쿼리로 분리

**예시**:
```
사용자 질문: "2024년 이후 작성된 AI 관련 문서를 찾아줘"

분석 결과:
- 메타데이터 필터: date >= 2024-01-01
- 검색 쿼리: "AI 인공지능 머신러닝"
```

### 4. Contextual Compression

**개념**: 검색된 문서에서 질문과 관련된 부분만 추출

**구현**:
1. Vector Store에서 문서 검색
2. LLM으로 각 문서를 요약/압축
3. 압축된 내용만 Agent에 전달

**장점**: 토큰 절약, 관련도 향상

## 트러블슈팅 체크리스트

### 시작 전 체크리스트

- [ ] n8n이 정상 실행 중인가?
- [ ] Supabase 프로젝트가 활성 상태인가?
- [ ] OpenAI API 키가 유효한가?
- [ ] Google Drive 인증이 완료되었는가?
- [ ] 필요한 테이블이 모두 생성되었는가?

### 워크플로우 1 (문서 처리) 체크리스트

- [ ] Google Drive Trigger가 올바른 폴더를 모니터링하는가?
- [ ] 파일 다운로드가 성공하는가?
- [ ] 텍스트 추출이 정상적으로 되는가?
- [ ] 청크 분할이 적절한가?
- [ ] 임베딩 생성이 성공하는가?
- [ ] Supabase에 데이터가 저장되는가?

### 워크플로우 2 (AI Agent) 체크리스트

- [ ] Chat Trigger가 활성화되었는가?
- [ ] AI Agent 설정이 올바른가?
- [ ] 모든 Tool이 제대로 연결되었는가?
- [ ] Memory가 작동하는가?
- [ ] Vector Store 검색이 결과를 반환하는가?
- [ ] Agent가 문서를 참조하여 답변하는가?

### 성능 체크리스트

- [ ] 검색 응답 시간이 5초 이내인가?
- [ ] 검색 결과의 관련도가 높은가?
- [ ] 메모리 사용량이 적정한가?
- [ ] 에러율이 5% 미만인가?
- [ ] 비용이 예산 내인가?

## 참고 자료

### 공식 문서

- [n8n 공식 문서](https://docs.n8n.io/)
- [Supabase Vector Store 가이드](https://supabase.com/docs/guides/ai)
- [OpenAI Embeddings API](https://platform.openai.com/docs/guides/embeddings)
- [OpenAI Chat Completions API](https://platform.openai.com/docs/guides/chat)
- [pgvector 문서](https://github.com/pgvector/pgvector)

### 학습 자료

- [RAG 시스템 개념 이해하기](https://www.anthropic.com/index/retrieval-augmented-generation-rag)
- [Vector Database 비교](https://supabase.com/blog/vector-databases-comparison)
- [LangChain RAG 튜토리얼](https://python.langchain.com/docs/use_cases/question_answering/)

### 커뮤니티

- [n8n Community Forum](https://community.n8n.io/)
- [Supabase Discord](https://discord.supabase.com/)
- [n8n Discord](https://discord.gg/n8n)

### 도구 및 리소스

- [n8n 워크플로우 템플릿](https://n8n.io/workflows/)
- [Supabase 프로젝트 템플릿](https://supabase.com/templates)
- [OpenAI Playground](https://platform.openai.com/playground)

## 결론

n8n과 Supabase를 활용한 RAG 시스템은 강력하면서도 비용 효율적인 솔루션입니다. 이 가이드에서 다룬 내용을 바탕으로:

> ### 핵심 요약
>
> 1. **간편한 구축**: 코딩 없이 노드 연결만으로 RAG 시스템 구축
> 2. **확장성**: 다양한 Tool과 통합하여 기능 확장 가능
> 3. **비용 효율**: 오픈소스 n8n과 무료 티어 Supabase 활용
> 4. **실용성**: 문서 검색, 고객 지원, 지식 관리 등 다양한 용도로 활용

### 다음 단계

이제 다음과 같은 방향으로 시스템을 발전시킬 수 있습니다:

1. **성능 최적화**: 청크 크기, Top K, 모델 선택 등을 실험하며 최적화
2. **기능 확장**: 추가 Tool 연결로 더 많은 작업 자동화
3. **통합 확대**: 카카오톡, 슬랙 등 다양한 플랫폼과 연동
4. **고급 기법**: HyDE, Re-ranking 등 고급 RAG 기법 적용

### 마지막 조언

RAG 시스템의 성공은 **데이터 품질**에 달려 있습니다. 깨끗하고 구조화된 문서를 준비하고, 지속적으로 개선해 나가세요. 사용자 피드백을 수집하고 반영하는 것도 잊지 마세요.

질문이나 문제가 있다면 n8n 커뮤니티나 Supabase Discord에서 도움을 받을 수 있습니다. 함께 더 나은 AI 시스템을 만들어가세요!
